{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention Unet(2019).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g61ZzKSSLYhj"
      },
      "source": [
        "def attention_block_2d(x, g, inter_channel):\n",
        "    # theta_x(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    theta_x = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(x)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    phi_g = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(g)\n",
        "\n",
        "    # f(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "\n",
        "    psi_f = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1),padding='same')(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "    \n",
        "def attention_up_and_concate(down_layer, layer):\n",
        "\n",
        "    in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2),interpolation = 'nearest')(down_layer)  \n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
        "\n",
        "    concate = concatenate([up, layer], axis=3)\n",
        "\n",
        "    return concate\n",
        "\n",
        "def down_block(x, filt):\n",
        "    cn = Conv2D(filters = filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
        "    d1 =  Dropout(0.2)(cn)\n",
        "    cn1 = Conv2D(filters = filt,  kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(d1)\n",
        "    p = MaxPooling2D((2, 2), strides=(2, 2),padding='same')(cn1)\n",
        "    return cn1, p\n",
        "\n",
        "def up_block(x, skip, filt):\n",
        "    concat = attention_up_and_concate(x, skip)\n",
        "    cnn = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(concat)\n",
        "    d2 =  Dropout(0.2)(cnn)     \n",
        "    cnn1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(d2)\n",
        "    return cnn1\n",
        "\n",
        "def bottleneck(x, filt):\n",
        "    cnt = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
        "    d3 = Dropout(0.2)(cnt)\n",
        "    cnt1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "               use_bias=True, kernel_initializer='glorot_normal')(d3)\n",
        "    return cnt1\n",
        "\n",
        "\n",
        "def att_UNet():\n",
        "    f = [64, 128, 256, 512, 1024]\n",
        "    #inputs = keras.layers.Input((image_size, image_size, 3))\n",
        "    inputs= Input((512,512,3))\n",
        "    \n",
        "    # p0 = inputs\n",
        "    c1, p1 = down_block(inputs, f[0]) #128 -> 64\n",
        "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
        "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
        "    c4, p4 = down_block(p3, f[3]) #16->8\n",
        "    pd1 = Dropout(0.2)(p4)   \n",
        "    bn = bottleneck(pd1, f[4])\n",
        "    pd2 = Dropout(0.2)(bn)   \n",
        "    u1 = up_block(pd2, c4, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
        "    \n",
        "    outputs = Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), padding='same', activation='sigmoid')(u4)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7lk8CMKLZQT"
      },
      "source": [
        "model_attUnet = att_UNet()\n",
        "adam = keras.optimizers.Adam(lr = 0.001)\n",
        "model_attUnet.compile(optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = [\"acc\"])\n",
        "model_attUnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}