{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dist(2019).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJgmt4k2L15j"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from  tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python import control_flow_ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvdgnDjOL2er"
      },
      "source": [
        "def CropAndMerge(Input1, Input2, name=\"bridge\"):\n",
        "        \"\"\"\n",
        "        Crop input1 so that it matches input2 and then\n",
        "        return the concatenation of both channels.\n",
        "        \"\"\"\n",
        "        Size1_x = (Input1).shape[1]\n",
        "        Size2_x = (Input2).shape[1]\n",
        "\n",
        "        Size1_y = (Input1).shape[2]\n",
        "        Size2_y = (Input2).shape[2]\n",
        "   \n",
        "        diff_x = tf.divide(tf.subtract(Size1_x, Size2_x), 2)\n",
        "        diff_y = tf.divide(tf.subtract(Size1_y, Size2_y), 2)\n",
        "        diff_x = tf.cast(diff_x, tf.int32)\n",
        "        Size2_x = tf.cast(Size2_x, tf.int32)\n",
        "        diff_y = tf.cast(diff_y, tf.int32)\n",
        "        Size2_y = tf.cast(Size2_y, tf.int32)\n",
        "        crop = tf.slice(Input1, [0, diff_x, diff_y, 0], [-1, Size2_x, Size2_y, -1])\n",
        "        concat = tf.concat([crop, Input2], axis=3)\n",
        "\n",
        "        return concat\n",
        "\n",
        "\n",
        "def bn_conv_relu(input, filters):\n",
        "    \n",
        "    x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "    x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "    x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "    x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def bn_upconv_relu(input, filters,conc):\n",
        "\n",
        "    x = Conv2DTranspose(filters=filters, kernel_size=(2, 2),activation='relu', strides=(2, 2), padding='same',kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),use_bias=True)(input)\n",
        "    x = CropAndMerge(Input1=x,Input2=conc,name='bridge')\n",
        "    \n",
        "    return x\n",
        "\n",
        "def dist(\n",
        "    \n",
        "    num_classes=1,\n",
        "    output_activation='sigmoid'):\n",
        "\n",
        "    inputs = Input((512,512,3))   \n",
        "    \n",
        "    filters = [32,64,128,256,512]\n",
        " \n",
        "\n",
        "    # for l in range(num_layers):\n",
        "    x_conv1 = bn_conv_relu(inputs, filters[0])\n",
        "    x_pool1 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv1)\n",
        "    x_conv2 = bn_conv_relu(x_pool1, filters[1])\n",
        "    x_pool2 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv2)  \n",
        "    x_conv3 = bn_conv_relu(x_pool2, filters[2])\n",
        "    x_pool3 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv3)\n",
        "    x_conv4 = bn_conv_relu(x_pool3, filters[3])\n",
        "    x_pool4 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv4)\n",
        "    x_conv5 = bn_conv_relu(x_pool4, filters[4])\n",
        "\n",
        "# upsampling in the form of convtranspose\n",
        "\n",
        "    x_tconv5 = bn_upconv_relu(x_conv5, filters[3],x_conv4)\n",
        "    u_conv4 = bn_conv_relu(x_tconv5, filters[3])\n",
        "    x_tconv4 = bn_upconv_relu(u_conv4, filters[2],x_conv3)\n",
        "    u_conv3 = bn_conv_relu(x_tconv4, filters[2])\n",
        "    x_tconv3 = bn_upconv_relu(u_conv3, filters[1],x_conv2)\n",
        "    u_conv2 = bn_conv_relu(x_tconv3, filters[1])\n",
        "    x_tconv2 = bn_upconv_relu(u_conv2, filters[0],x_conv1)\n",
        "    u_conv1 = bn_conv_relu(x_tconv2, filters[0])\n",
        "              \n",
        "    outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='same') (u_conv1)       \n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x82MGXY3L6nL"
      },
      "source": [
        "\n",
        "model_dist = dist()\n",
        "adam = keras.optimizers.Adam(lr = 0.001,decay=5*1e-6)\n",
        "model_dist.compile(optimizer = \"adam\" , loss = \"binary_crossentropy\" , metrics = [\"acc\"])\n",
        "model_dist.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}