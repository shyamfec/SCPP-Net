{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block_2d(x, g, inter_channel):\n",
    "    # theta_x(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    theta_x = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(x)\n",
    "\n",
    "    # phi_g(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    phi_g = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(g)\n",
    "\n",
    "    # f(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "    # psi_f(?,g_height,g_width,1)\n",
    "\n",
    "    psi_f = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1),padding='same')(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "    # rate(?,x_height,x_width)\n",
    "\n",
    "    # att_x(?,x_height,x_width,x_channel)\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "    \n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2),interpolation = 'nearest')(down_layer)  \n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer], axis=3)\n",
    "\n",
    "    return concate\n",
    "\n",
    "def down_block(x, filt):\n",
    "    cn = Conv2D(filters = filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    d1 =  Dropout(0.2)(cn)\n",
    "    cn1 = Conv2D(filters = filt,  kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d1)\n",
    "    p = MaxPooling2D((2, 2), strides=(2, 2),padding='same')(cn1)\n",
    "    return cn1, p\n",
    "\n",
    "def up_block(x, skip, filt):\n",
    "    concat = attention_up_and_concate(x, skip)\n",
    "    cnn = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(concat)\n",
    "    d2 =  Dropout(0.2)(cnn)     \n",
    "    cnn1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d2)\n",
    "    return cnn1\n",
    "\n",
    "def bottleneck(x, filt):\n",
    "    cnt = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    d3 = Dropout(0.2)(cnt)\n",
    "    cnt1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d3)\n",
    "    return cnt1\n",
    "\n",
    "\n",
    "def att_UNet():\n",
    "    f = [64, 128, 256, 512, 1024]\n",
    "    #inputs = keras.layers.Input((image_size, image_size, 3))\n",
    "    inputs= Input((512,512,3))\n",
    "    \n",
    "    # p0 = inputs\n",
    "    c1, p1 = down_block(inputs, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    pd1 = Dropout(0.2)(p4)   \n",
    "    bn = bottleneck(pd1, f[4])\n",
    "    pd2 = Dropout(0.2)(bn)   \n",
    "    u1 = up_block(pd2, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "    \n",
    "    outputs = Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), padding='same', activation='sigmoid')(u4)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attUnet = att_UNet()\n",
    "adam = keras.optimizers.Adam(lr = 0.001)\n",
    "model_attUnet.compile(optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = [\"acc\"])\n",
    "model_attUnet.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
