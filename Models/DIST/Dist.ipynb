{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from  tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python import control_flow_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def CropAndMerge(Input1, Input2, name=\"bridge\"):\n",
    "        \"\"\"\n",
    "        Crop input1 so that it matches input2 and then\n",
    "        return the concatenation of both channels.\n",
    "        \"\"\"\n",
    "        Size1_x = (Input1).shape[1]\n",
    "        Size2_x = (Input2).shape[1]\n",
    "\n",
    "        Size1_y = (Input1).shape[2]\n",
    "        Size2_y = (Input2).shape[2]\n",
    "   \n",
    "        diff_x = tf.divide(tf.subtract(Size1_x, Size2_x), 2)\n",
    "        diff_y = tf.divide(tf.subtract(Size1_y, Size2_y), 2)\n",
    "        diff_x = tf.cast(diff_x, tf.int32)\n",
    "        Size2_x = tf.cast(Size2_x, tf.int32)\n",
    "        diff_y = tf.cast(diff_y, tf.int32)\n",
    "        Size2_y = tf.cast(Size2_y, tf.int32)\n",
    "        crop = tf.slice(Input1, [0, diff_x, diff_y, 0], [-1, Size2_x, Size2_y, -1])\n",
    "        concat = tf.concat([crop, Input2], axis=3)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "def bn_conv_relu(input, filters):\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
    "    x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
    "    x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
    "    x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def bn_upconv_relu(input, filters,conc):\n",
    "\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(2, 2),activation='relu', strides=(2, 2), padding='same',kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),use_bias=True)(input)\n",
    "    x = CropAndMerge(Input1=x,Input2=conc,name='bridge')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def dist(\n",
    "    \n",
    "    num_classes=1,\n",
    "    output_activation='sigmoid'):\n",
    "\n",
    "    inputs = Input((512,512,3))   \n",
    "    \n",
    "    filters = [32,64,128,256,512]\n",
    " \n",
    "\n",
    "    # for l in range(num_layers):\n",
    "    x_conv1 = bn_conv_relu(inputs, filters[0])\n",
    "    x_pool1 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv1)\n",
    "    x_conv2 = bn_conv_relu(x_pool1, filters[1])\n",
    "    x_pool2 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv2)  \n",
    "    x_conv3 = bn_conv_relu(x_pool2, filters[2])\n",
    "    x_pool3 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv3)\n",
    "    x_conv4 = bn_conv_relu(x_pool3, filters[3])\n",
    "    x_pool4 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv4)\n",
    "    x_conv5 = bn_conv_relu(x_pool4, filters[4])\n",
    "\n",
    "# upsampling in the form of convtranspose\n",
    "\n",
    "    x_tconv5 = bn_upconv_relu(x_conv5, filters[3],x_conv4)\n",
    "    u_conv4 = bn_conv_relu(x_tconv5, filters[3])\n",
    "    x_tconv4 = bn_upconv_relu(u_conv4, filters[2],x_conv3)\n",
    "    u_conv3 = bn_conv_relu(x_tconv4, filters[2])\n",
    "    x_tconv3 = bn_upconv_relu(u_conv3, filters[1],x_conv2)\n",
    "    u_conv2 = bn_conv_relu(x_tconv3, filters[1])\n",
    "    x_tconv2 = bn_upconv_relu(u_conv2, filters[0],x_conv1)\n",
    "    u_conv1 = bn_conv_relu(x_tconv2, filters[0])\n",
    "              \n",
    "    outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='same') (u_conv1)       \n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "# for dice cofficient\n",
    "smooth = 1.\n",
    "#def dice_coef(y_true, y_pred):\n",
    "#    y_true_f = K.flatten(y_true)\n",
    "#    y_pred_f = K.flatten(y_pred)\n",
    "#    intersection = K.sum(y_true_f * y_pred_f)\n",
    "#    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "#def dice_coef_loss(y_true, y_pred):\n",
    "#    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "#def binary_cross(y_true, y_pred):\n",
    "#    return K.binary_crossentropy(y_true,y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dist = dist()\n",
    "adam = keras.optimizers.Adam(lr = 0.001,decay=5*1e-6)\n",
    "model_dist.compile(optimizer = \"adam\" , loss = \"binary_crossentropy\" , metrics = [\"acc\"])\n",
    "model_dist.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
